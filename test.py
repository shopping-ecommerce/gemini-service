# """
# Setup v√† Test Semantic Search v·ªõi credentials.json
# Ch·∫°y: python setup_and_test.py
# """

# import os
# import json
# import vertexai
# from vertexai.language_models import TextEmbeddingModel, TextEmbeddingInput
# import numpy as np

# # ============= C·∫§U H√åNH =============
# CREDENTIALS_FILE = "credentials.json"  # ƒê∆∞·ªùng d·∫´n ƒë·∫øn file credentials
# LOCATION = "asia-southeast1"  # Ho·∫∑c: asia-southeast1

# def load_credentials():
#     """ƒê·ªçc v√† validate credentials.json"""
#     print("üîë ƒêang ki·ªÉm tra credentials...")
    
#     if not os.path.exists(CREDENTIALS_FILE):
#         print(f"‚ùå Kh√¥ng t√¨m th·∫•y file: {CREDENTIALS_FILE}")
#         print("\nüí° H∆∞·ªõng d·∫´n t·∫°o credentials.json:")
#         print("   1. V√†o Google Cloud Console")
#         print("   2. IAM & Admin > Service Accounts")
#         print("   3. T·∫°o Service Account v·ªõi role: Vertex AI User")
#         print("   4. T·∫°o key (JSON) v√† l∆∞u th√†nh credentials.json")
#         return None
    
#     try:
#         with open(CREDENTIALS_FILE, 'r') as f:
#             creds = json.load(f)
        
#         project_id = creds.get('project_id')
#         if not project_id:
#             print("‚ùå File credentials.json kh√¥ng h·ª£p l·ªá (thi·∫øu project_id)")
#             return None
        
#         print(f"‚úÖ Credentials h·ª£p l·ªá")
#         print(f"üìç Project ID: {project_id}")
#         print(f"üìç Service Account: {creds.get('client_email', 'N/A')}")
        
#         return project_id
        
#     except json.JSONDecodeError:
#         print("‚ùå File credentials.json kh√¥ng ƒë√∫ng ƒë·ªãnh d·∫°ng JSON")
#         return None
#     except Exception as e:
#         print(f"‚ùå L·ªói ƒë·ªçc credentials: {e}")
#         return None

# def setup_vertex_ai(project_id):
#     """Thi·∫øt l·∫≠p Vertex AI v·ªõi credentials"""
#     print("\nüîß ƒêang thi·∫øt l·∫≠p Vertex AI...")
    
#     try:
#         # Set environment variable cho credentials
#         os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = CREDENTIALS_FILE
        
#         # Kh·ªüi t·∫°o Vertex AI
#         vertexai.init(project=project_id, location=LOCATION)
        
#         # Load model
#         model = TextEmbeddingModel.from_pretrained("gemini-embedding-001")
        
#         print("‚úÖ Vertex AI ƒë√£ s·∫µn s√†ng!")
#         return model
        
#     except Exception as e:
#         print(f"‚ùå L·ªói setup Vertex AI: {e}")
#         print("\nüí° C√≥ th·ªÉ do:")
#         print("   1. Ch∆∞a enable Vertex AI API")
#         print("   2. Service Account ch∆∞a c√≥ quy·ªÅn Vertex AI User")
#         print("   3. Ch∆∞a enable billing cho project")
#         return None

# def quick_test(model):
#     """Test nhanh embedding"""
#     print("\n" + "="*60)
#     print("‚ö° QUICK TEST")
#     print("="*60)
    
#     test_text = "Hello, this is a test!"
#     print(f"Text: {test_text}")
    
#     try:
#         input_data = TextEmbeddingInput(text=test_text, task_type="RETRIEVAL_DOCUMENT")
#         embedding = model.get_embeddings([input_data])[0]
        
#         print(f"‚úÖ Embedding th√†nh c√¥ng!")
#         print(f"   - Dimension: {len(embedding.values)}")
#         print(f"   - Sample values: {embedding.values[:3]}")
#         return True
#     except Exception as e:
#         print(f"‚ùå L·ªói: {e}")
#         return False

# def demo_semantic_search(model):
#     """Demo semantic search ho√†n ch·ªânh"""
#     print("\n" + "="*60)
#     print("üéØ DEMO SEMANTIC SEARCH")
#     print("="*60)
    
#     # D·ªØ li·ªáu m·∫´u
#     documents = [
#         "Python l√† ng√¥n ng·ªØ l·∫≠p tr√¨nh m·∫°nh m·∫Ω cho AI v√† data science",
#         "Machine learning cho ph√©p m√°y t√≠nh h·ªçc t·ª´ d·ªØ li·ªáu",
#         "Deep learning s·ª≠ d·ª•ng m·∫°ng neural nhi·ªÅu l·ªõp",
#         "TensorFlow l√† framework ph·ªï bi·∫øn cho ML",
#         "Google Cloud Platform cung c·∫•p nhi·ªÅu d·ªãch v·ª• cloud",
#         "Vertex AI l√† n·ªÅn t·∫£ng ML th·ªëng nh·∫•t tr√™n GCP",
#         "JavaScript l√† ng√¥n ng·ªØ l·∫≠p tr√¨nh cho web",
#         "React gi√∫p x√¢y d·ª±ng giao di·ªán ng∆∞·ªùi d√πng",
#         "Docker gi√∫p containerize ·ª©ng d·ª•ng",
#         "Kubernetes qu·∫£n l√Ω container ·ªü quy m√¥ l·ªõn"
#     ]
    
#     print(f"\nüìö ƒêang index {len(documents)} documents...")
    
#     try:
#         # T·∫°o embeddings cho documents
#         doc_inputs = [
#             TextEmbeddingInput(text=doc, task_type="RETRIEVAL_DOCUMENT") 
#             for doc in documents
#         ]
#         doc_embeddings = model.get_embeddings(doc_inputs)
#         print("‚úÖ Index ho√†n t·∫•t!")
        
#         # Test v·ªõi nhi·ªÅu queries
#         queries = [
#             "H·ªçc m√°y l√† g√¨?",
#             "Framework cho AI",
#             "C√¥ng c·ª• ph√°t tri·ªÉn web",
#             "N·ªÅn t·∫£ng cloud c·ªßa Google"
#         ]
        
#         for query in queries:
#             print(f"\n{'='*60}")
#             print(f"üîç Query: '{query}'")
#             print("-" * 60)
            
#             # T·∫°o embedding cho query
#             query_input = TextEmbeddingInput(text=query, task_type="RETRIEVAL_QUERY")
#             query_embedding = model.get_embeddings([query_input])[0]
            
#             # T√≠nh cosine similarity
#             query_vec = np.array(query_embedding.values)
#             similarities = []
            
#             for doc_emb in doc_embeddings:
#                 doc_vec = np.array(doc_emb.values)
#                 sim = np.dot(query_vec, doc_vec) / (
#                     np.linalg.norm(query_vec) * np.linalg.norm(doc_vec)
#                 )
#                 similarities.append(sim)
            
#             # Hi·ªÉn th·ªã top 3 k·∫øt qu·∫£
#             top_indices = np.argsort(similarities)[-3:][::-1]
            
#             for i, idx in enumerate(top_indices, 1):
#                 score = similarities[idx]
#                 emoji = "ü•á" if i == 1 else "ü•à" if i == 2 else "ü•â"
#                 print(f"{emoji} Top {i}: [Score: {score:.4f}]")
#                 print(f"   {documents[idx]}")
        
#         return True
        
#     except Exception as e:
#         print(f"‚ùå L·ªói: {e}")
#         return False

# def main():
#     print("üöÄ GEMINI SEMANTIC SEARCH - SETUP & TEST")
#     print("="*60)
    
#     # B∆∞·ªõc 1: Load credentials
#     project_id = load_credentials()
#     if not project_id:
#         return
    
#     # B∆∞·ªõc 2: Setup Vertex AI
#     model = setup_vertex_ai(project_id)
#     if not model:
#         return
    
#     # B∆∞·ªõc 3: Quick test
#     if not quick_test(model):
#         return
    
#     # B∆∞·ªõc 4: Demo semantic search
#     demo_semantic_search(model)
    
#     print("\n" + "="*60)
#     print("‚ú® SETUP & TEST HO√ÄN T·∫§T!")
#     print("="*60)
#     print("\nüí° B√¢y gi·ªù b·∫°n c√≥ th·ªÉ:")
#     print("   - Import v√† s·ª≠ d·ª•ng class GeminiSemanticSearch")
#     print("   - T√≠ch h·ª£p v√†o ·ª©ng d·ª•ng c·ªßa b·∫°n")
#     print("   - Scale l√™n v·ªõi nhi·ªÅu documents h∆°n")

# if __name__ == "__main__":
#     main()